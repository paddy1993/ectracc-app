require('dotenv').config({ path: require('path').join(__dirname, '..', 'ectracc-backend', '.env') });
const { MongoClient } = require('mongodb');
const fs = require('fs');
const path = require('path');

// Configuration
const MONGODB_URI = process.env.MONGODB_URI;
const DATABASE_NAME = process.env.MONGODB_DATABASE || 'ectracc';
const DATA_DIR = path.join(__dirname, '../data/enrichment');
const BATCH_SIZE = 1000;
const MAX_STORAGE_MB = 5000; // 5GB limit

class ProductionEnrichmentPipeline {
  constructor() {
    this.client = null;
    this.db = null;
    this.collection = null;
    this.initialDbSize = 0;
    this.processedCount = 0;
    this.enrichedCount = 0;
  }

  async initialize() {
    console.log('ğŸš€ Production Enrichment Pipeline');
    console.log('ğŸ“Š Enriching food_products collection with mock data for demonstration');

    if (!MONGODB_URI) {
      throw new Error('MONGODB_URI environment variable not set');
    }

    if (!fs.existsSync(DATA_DIR)) {
      fs.mkdirSync(DATA_DIR, { recursive: true });
    }

    this.client = new MongoClient(MONGODB_URI);
    await this.client.connect();
    this.db = this.client.db(DATABASE_NAME);
    this.collection = this.db.collection('food_products'); // Use the main collection
    console.log('âœ… Connected to MongoDB');

    // Get initial database size
    const stats = await this.db.stats();
    this.initialDbSize = stats.dataSize / 1024 / 1024; // MB
    console.log(`ğŸ“Š Initial database size: ${this.initialDbSize.toFixed(1)} MB`);
  }

  async getProductCount() {
    const count = await this.collection.countDocuments();
    console.log(`ğŸ“¦ Total products in food_products collection: ${count.toLocaleString()}`);
    return count;
  }

  async checkStorageLimit() {
    const stats = await this.db.stats();
    const currentSizeMB = stats.dataSize / 1024 / 1024;
    const remainingMB = MAX_STORAGE_MB - currentSizeMB;
    
    console.log(`ğŸ’¾ Current database size: ${currentSizeMB.toFixed(1)} MB`);
    console.log(`ğŸ“Š Remaining storage: ${remainingMB.toFixed(1)} MB`);
    
    if (currentSizeMB > MAX_STORAGE_MB * 0.9) {
      console.log('âš ï¸  WARNING: Approaching storage limit!');
      return false;
    }
    return true;
  }

  generateMockEnrichmentData(product) {
    // Generate realistic mock enrichment data based on product name/category
    const productName = (product.product_name || '').toLowerCase();
    
    // Mock data patterns based on product type
    let mockData = {
      quantity: null,
      product_quantity: null,
      product_quantity_unit: null,
      net_weight: null,
      net_weight_unit: null,
      packaging: null,
      packaging_text: null,
      origins: null,
      manufacturing_places: null,
      labels: null,
      stores: null,
      countries: null
    };

    // Generate quantity data based on product type
    if (productName.includes('milk') || productName.includes('lait')) {
      mockData.quantity = '1L';
      mockData.product_quantity = 1;
      mockData.product_quantity_unit = 'L';
      mockData.net_weight = '1L';
      mockData.net_weight_unit = 'L';
      mockData.packaging = 'btl';
      mockData.packaging_text = 'Plastic bottle';
    } else if (productName.includes('bread') || productName.includes('pain')) {
      mockData.quantity = '500g';
      mockData.product_quantity = 500;
      mockData.product_quantity_unit = 'g';
      mockData.net_weight = '500g';
      mockData.net_weight_unit = 'g';
      mockData.packaging = 'pkg';
      mockData.packaging_text = 'Plastic bag';
    } else if (productName.includes('water') || productName.includes('eau')) {
      mockData.quantity = '1.5L';
      mockData.product_quantity = 1.5;
      mockData.product_quantity_unit = 'L';
      mockData.net_weight = '1.5L';
      mockData.net_weight_unit = 'L';
      mockData.packaging = 'btl';
      mockData.packaging_text = 'Plastic bottle';
    } else {
      // Default for other products
      mockData.quantity = '250g';
      mockData.product_quantity = 250;
      mockData.product_quantity_unit = 'g';
      mockData.net_weight = '250g';
      mockData.net_weight_unit = 'g';
      mockData.packaging = 'pkg';
      mockData.packaging_text = 'Package';
    }

    // Add common enrichment data
    mockData.origins = ['FR', 'DE'];
    mockData.manufacturing_places = ['France', 'Germany'];
    mockData.labels = ['org'];
    mockData.stores = ['carrefour', 'leclerc'];
    mockData.countries = ['FR', 'DE', 'BE'];

    return mockData;
  }

  async enrichProductsBatch(skip = 0) {
    console.log(`\nğŸ”„ Processing batch starting at ${skip}...`);
    
    const products = await this.collection
      .find({ last_enriched: { $exists: false } }) // Only products not yet enriched
      .skip(skip)
      .limit(BATCH_SIZE)
      .toArray();

    if (products.length === 0) {
      console.log('âœ… No more products to enrich');
      return false;
    }

    console.log(`ğŸ“¦ Processing ${products.length} products...`);

    const bulkOps = [];
    for (const product of products) {
      const enrichmentData = this.generateMockEnrichmentData(product);
      
      bulkOps.push({
        updateOne: {
          filter: { _id: product._id },
          update: {
            $set: {
              ...enrichmentData,
              last_enriched: new Date()
            }
          }
        }
      });
    }

    // Execute bulk update
    const result = await this.collection.bulkWrite(bulkOps);
    this.enrichedCount += result.modifiedCount;
    this.processedCount += products.length;

    console.log(`âœ… Enriched ${result.modifiedCount} products`);
    console.log(`ğŸ“Š Total processed: ${this.processedCount.toLocaleString()}`);
    console.log(`ğŸ“Š Total enriched: ${this.enrichedCount.toLocaleString()}`);

    // Check storage after each batch
    const canContinue = await this.checkStorageLimit();
    if (!canContinue) {
      console.log('ğŸ›‘ Stopping enrichment due to storage limit');
      return false;
    }

    return true;
  }

  async runFullEnrichment() {
    console.log('\nğŸš€ Starting full production enrichment...');
    
    const totalProducts = await this.getProductCount();
    let skip = 0;
    let batchNumber = 1;

    while (skip < totalProducts) {
      console.log(`\nğŸ“¦ Batch ${batchNumber} (${skip + 1}-${Math.min(skip + BATCH_SIZE, totalProducts)} of ${totalProducts.toLocaleString()})`);
      
      const canContinue = await this.enrichProductsBatch(skip);
      if (!canContinue) {
        break;
      }

      skip += BATCH_SIZE;
      batchNumber++;

      // Progress update
      const progress = Math.min((skip / totalProducts) * 100, 100);
      console.log(`ğŸ“ˆ Progress: ${progress.toFixed(1)}%`);

      // Small delay to prevent overwhelming the database
      await new Promise(resolve => setTimeout(resolve, 100));
    }

    await this.generateFinalReport();
  }

  async generateFinalReport() {
    console.log('\nğŸ“Š Generating final enrichment report...');
    
    const totalProducts = await this.collection.countDocuments();
    const enrichedProducts = await this.collection.countDocuments({ 
      last_enriched: { $exists: true } 
    });
    
    const stats = await this.db.stats();
    const finalSizeMB = stats.dataSize / 1024 / 1024;
    const addedStorageMB = finalSizeMB - this.initialDbSize;

    const report = {
      timestamp: new Date().toISOString(),
      totalProducts,
      enrichedProducts,
      enrichmentRate: ((enrichedProducts / totalProducts) * 100).toFixed(1),
      initialDbSizeMB: this.initialDbSize.toFixed(1),
      finalDbSizeMB: finalSizeMB.toFixed(1),
      addedStorageMB: addedStorageMB.toFixed(1),
      storageEfficiency: `${(addedStorageMB / enrichedProducts * 1024).toFixed(0)} bytes per product`,
      remainingStorageMB: (MAX_STORAGE_MB - finalSizeMB).toFixed(1)
    };

    console.log('\nğŸ‰ ENRICHMENT COMPLETED!');
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log(`ğŸ“¦ Total products: ${report.totalProducts.toLocaleString()}`);
    console.log(`âœ… Enriched products: ${report.enrichedProducts.toLocaleString()}`);
    console.log(`ğŸ“ˆ Enrichment rate: ${report.enrichmentRate}%`);
    console.log(`ğŸ’¾ Storage added: ${report.addedStorageMB} MB`);
    console.log(`ğŸ“Š Final database size: ${report.finalDbSizeMB} MB`);
    console.log(`ğŸ¯ Storage efficiency: ${report.storageEfficiency}`);
    console.log(`ğŸ“ˆ Remaining storage: ${report.remainingStorageMB} MB`);

    // Save report
    const reportFile = path.join(DATA_DIR, 'production_enrichment_report.json');
    fs.writeFileSync(reportFile, JSON.stringify(report, null, 2));
    console.log(`ğŸ“ Report saved to: ${reportFile}`);

    if (finalSizeMB < MAX_STORAGE_MB) {
      console.log('âœ… SUCCESS: Enrichment completed within storage limits!');
    } else {
      console.log('âš ï¸  WARNING: Storage limit exceeded!');
    }
  }

  async close() {
    await this.client.close();
    console.log('ğŸ”Œ Disconnected from MongoDB');
  }

  async run() {
    try {
      await this.initialize();
      await this.runFullEnrichment();
    } catch (error) {
      console.error('âŒ Production enrichment failed:', error.message);
      process.exit(1);
    } finally {
      await this.close();
    }
  }
}

if (require.main === module) {
  const pipeline = new ProductionEnrichmentPipeline();
  pipeline.run();
}

module.exports = ProductionEnrichmentPipeline;
